{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import concurrent.futures\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages = pd.read_csv('letsreadasia_pages.csv')\n",
    "#Filter Pages that not have \"Badan Pengembangan\" or \"lembaga\" in 'extractedLongContentValue' column\n",
    "df_pages = df_pages[~df_pages['extractedLongContentValue'].str.contains('Badan Pengembangan|lembaga|Lembaga|Foundation|SMART', na=False, regex=True)]\n",
    "df_pages = df_pages.dropna(subset=['id','imageServingUrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://lh3.googleusercontent.com/xvhhn13sPGzf0EvoBT2Q5J3GqYEahWanm2zUAqfArZ5t1e_XpiJF9KgCMfz4DvEHYiQ8KBKuDhrYimleODZcnHs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pages.iloc[10]['imageServingUrl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_scrape_image(row):\n",
    "    try:\n",
    "        image_url = row['imageServingUrl']\n",
    "        image_name = f\"{row['id']}.jpg\"\n",
    "        image_path = os.path.join('./images', image_name)\n",
    "        r = requests.get(image_url, allow_redirects=True)\n",
    "        open(image_path, 'wb').write(r.content)\n",
    "        return image_path\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7245it [02:15, 53.55it/s] \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./images'):\n",
    "    os.mkdir('./images')\n",
    "image_paths = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "\n",
    "    futures = []\n",
    "\n",
    "    for index,row in df_pages.iterrows():\n",
    "        futures.append(executor.submit(row_scrape_image, row=row))\n",
    "\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures)):\n",
    "        image_paths.append(future.result())\n",
    "df_pages['image_path'] = image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages.to_csv('letsreadasia_pages_images_filtered.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLIP Captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages = pd.read_csv('letsreadasia_pages_images_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 16:01:15.803766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 16:01:17.040103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/wsl/lib::/home/karuniaperjuangan/anaconda3/lib::/usr/local/cuda-11.2/targets/x86_64-linux/lib::\n",
      "2023-03-22 16:01:17.041956: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/lib/wsl/lib::/home/karuniaperjuangan/anaconda3/lib::/usr/local/cuda-11.2/targets/x86_64-linux/lib::\n",
      "2023-03-22 16:01:17.041964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"/mnt/e/AI-Project/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"/mnt/e/AI-Project/blip-image-captioning-large\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corrupted_paths = []\n",
    "def predict_caption(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(img, return_tensors=\"pt\",max_length=75).to(\"cuda\", torch.float16)\n",
    "    outputs = model.generate(**inputs)\n",
    "    caption = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "    return caption\n",
    "\n",
    "def predict_caption_in_batch(image_paths):\n",
    "    imgs = []\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(image_path).convert('RGB')\n",
    "        except:\n",
    "            img = Image.new('RGB', (224, 224))\n",
    "            list_corrupted_paths.append(image_path)\n",
    "            print(f\"{image_path} corrupted or not found!\")\n",
    "        imgs.append(img)\n",
    "    inputs = processor(imgs, return_tensors=\"pt\").to(\"cuda\", torch.float16)\n",
    "    outputs = model.generate(**inputs)\n",
    "    captions = processor.batch_decode(outputs, skip_special_tokens=True, max_length=75)\n",
    "    return captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/114 [00:13<08:12,  4.44s/it]/home/karuniaperjuangan/anaconda3/lib/python3.9/site-packages/PIL/Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 95/114 [07:27<01:26,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/5008034443034624.jpg corrupted or not found!\n",
      "./images/5289509419745280.jpg corrupted or not found!\n",
      "./images/6263704907677696.jpg corrupted or not found!\n",
      "./images/5916196419403776.jpg corrupted or not found!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [08:49<00:00,  4.65s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "image_paths = df_pages['image_path'].tolist()\n",
    "\n",
    "captions = []\n",
    "for i in tqdm(range(0, len(image_paths), BATCH_SIZE)):\n",
    "    batch_image_paths = image_paths[i:i+BATCH_SIZE]\n",
    "    batch_captions = predict_caption_in_batch(batch_image_paths)\n",
    "    captions.extend(batch_captions)\n",
    "    \n",
    "df_pages['caption'] = captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>extractedLongContentValue</th>\n",
       "      <th>bookId</th>\n",
       "      <th>pageNum</th>\n",
       "      <th>imageUrl</th>\n",
       "      <th>imageServingUrl</th>\n",
       "      <th>thumborImageUrl</th>\n",
       "      <th>thumborImageUrlWithourResizing</th>\n",
       "      <th>imageWidth</th>\n",
       "      <th>imageHeight</th>\n",
       "      <th>...</th>\n",
       "      <th>audio</th>\n",
       "      <th>video</th>\n",
       "      <th>translatedState</th>\n",
       "      <th>idClone</th>\n",
       "      <th>deleted</th>\n",
       "      <th>bookName</th>\n",
       "      <th>bookTotalPages</th>\n",
       "      <th>isEnding</th>\n",
       "      <th>image_path</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6136</th>\n",
       "      <td>5916196419403776</td>\n",
       "      <td>Kuda Nil ingin menari. Ia melompat-lompat di t...</td>\n",
       "      <td>f4b70634-bd75-4568-bd69-c26edad2e7e1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://storage.googleapis.com/lets-read-asia/...</td>\n",
       "      <td>https://lh3.googleusercontent.com/yvHbe8NjlQgS...</td>\n",
       "      <td>https://letsread-images.hamropatro.com/ilKchoC...</td>\n",
       "      <td>https://letsread-images.hamropatro.com/bvSkkDi...</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>5916196419403776</td>\n",
       "      <td>False</td>\n",
       "      <td>Kuda Nil ingin menari</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>./images/5775458931048448.jpg</td>\n",
       "      <td>cartoon hippoid hippoid hippoid hippoid hippoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                          extractedLongContentValue  \\\n",
       "6136  5916196419403776  Kuda Nil ingin menari. Ia melompat-lompat di t...   \n",
       "\n",
       "                                    bookId  pageNum  \\\n",
       "6136  f4b70634-bd75-4568-bd69-c26edad2e7e1        1   \n",
       "\n",
       "                                               imageUrl  \\\n",
       "6136  https://storage.googleapis.com/lets-read-asia/...   \n",
       "\n",
       "                                        imageServingUrl  \\\n",
       "6136  https://lh3.googleusercontent.com/yvHbe8NjlQgS...   \n",
       "\n",
       "                                        thumborImageUrl  \\\n",
       "6136  https://letsread-images.hamropatro.com/ilKchoC...   \n",
       "\n",
       "                         thumborImageUrlWithourResizing  imageWidth  \\\n",
       "6136  https://letsread-images.hamropatro.com/bvSkkDi...         800   \n",
       "\n",
       "      imageHeight  ... audio video translatedState           idClone deleted  \\\n",
       "6136          800  ...   NaN   NaN           False  5916196419403776   False   \n",
       "\n",
       "                   bookName  bookTotalPages  isEnding  \\\n",
       "6136  Kuda Nil ingin menari              13     False   \n",
       "\n",
       "                         image_path  \\\n",
       "6136  ./images/5775458931048448.jpg   \n",
       "\n",
       "                                                caption  \n",
       "6136  cartoon hippoid hippoid hippoid hippoid hippoi...  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pages[df_pages['id'].astype(str).str.contains('5916196419403776')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    \n",
    "df_pages = df_pages[~df_pages['image_path'].isin(list_corrupted_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pages.to_csv('letsreadasia_pages_images_filtered_captioned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
